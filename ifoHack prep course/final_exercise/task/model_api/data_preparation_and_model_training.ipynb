{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Model Training\n",
    "\n",
    "In this notebook, we load the [Iris plants dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris), extract features, and train a Random Forest classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We use the [Iris plants dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) to predict the class of Iris flowers.\n",
    "It contains 150 samples (50 for each instance), and the following 4 numeric, predictive attributes.\n",
    "\n",
    "- sepal length in cm\n",
    "- sepal width in cm\n",
    "- petal length in cm\n",
    "- petal width in cm\n",
    "\n",
    "The class names are Iris-Setosa (`0`), Iris-Versicolour (`1`), and Iris-Virginica (`2`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min(axis=0), X.max(axis=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data to gain some insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Petal Length and Width\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_title('Iris Classification Based on Sepal Length and Width')\n",
    "ax.set_xlabel('Sepal Length (cm)')\n",
    "ax.set_ylabel('Sepal Width (cm)')\n",
    "ax.grid(True, linestyle='-', color='0.5')\n",
    "ax.scatter(X[:, 0], X[:, 1], s=32, c=y, marker='o')\n",
    "\n",
    "# Sepal Length and Width\n",
    "ax = fig.add_subplot(122)\n",
    "ax.set_title(\"Iris Classification Based on Petal Length and Width\")\n",
    "ax.set_xlabel('Petal Length (cm)')\n",
    "ax.set_ylabel('Petal width (cm)')\n",
    "ax.grid(True, linestyle='-', color='0.5')\n",
    "ax.scatter(X[:, 2], X[:, 3], s=32, c=y, marker='s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Split the data into train and test sets. Use $60%$ samples for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = None  # todo\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Training\n",
    "\n",
    "### Model Training and Logging\n",
    "\n",
    "Let's use random forest regression to predict house prices.\n",
    "Therefore, we want to find a reasonable maximum depth for the single decision trees.\n",
    "We keep track of several tries and their mean squared error using MLflow.\n",
    "\n",
    "Please note that we ignore best practices like cross validation, feature selection and randomised parameter search for demonstration purposes.\n",
    "\n",
    "**Task:** Setup the pipeline factory with a random forest classifier using `max_depth=3` and a specified number of estimators. You might add additional pipeline steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(n_estimators: int) -> Pipeline:\n",
    "    return Pipeline(\n",
    "        steps=[ # todo\n",
    "               ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Choose reasonable hyperparameters to try, and execute the training process. Log the accuracy and according parameters. You might add further metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_to_try = []  # todo: choose hyperparameters to try\n",
    "REGISTERED_MODEL_NAME = \"iris_forest_classifier\"\n",
    "\n",
    "for max_depth in n_estimators_to_try:\n",
    "    with mlflow.start_run():\n",
    "        # build a pipeline with a ridge regression model\n",
    "        model_pipeline = create_pipeline(n_estimators=max_depth)\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # calculaye metrics using the test data\n",
    "        y_pred = model_pipeline.predict(X=X_test)\n",
    "        acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "        # todo: log parameters and metrics\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipeline, artifact_path=\"iris\", registered_model_name=REGISTERED_MODEL_NAME)\n",
    "\n",
    "        print(\n",
    "            f\"Model saved in run {mlflow.active_run().info.run_uuid}. Acc={acc}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Runs in the MLflow Web-UI\n",
    "\n",
    "**Task:** Inspect the training runs with their parameters and metrics with MLflow's web-UI.\n",
    "Store the best model in the model registry, and stage it for production (**either in the web UI, or using the Python interface**).\n",
    "\n",
    "Just execute this cell and visit the uri in your web browser.\n",
    "Terminate this cell or the notebook to stop the server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui -p 5002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# only necessary, if you did not stage a model for production using the web interface\n",
    "client = mlflow.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=REGISTERED_MODEL_NAME,\n",
    "    version=None,  # todo: choose the model version, if not already done in the web interface\n",
    "    stage=\"Production\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Let's use our production model to generate a Docker image for the model endpoint.\n",
    "\n",
    "Please note that the first run of this cell might take some minutes.\n",
    "In the meantime, you can start with the next tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.build_docker(\n",
    "    model_uri=f\"models:/{REGISTERED_MODEL_NAME}/Production\", name=\"iris_model_api\", env_manager=\"local\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifo_tasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
